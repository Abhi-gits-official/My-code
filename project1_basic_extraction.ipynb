{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ead0c8b6",
   "metadata": {},
   "source": [
    "# HR Workflow Simulation: CV Analysis & Role Matching System üü¢\n",
    "\n",
    "## üéØ Project Overview\n",
    "\n",
    " Welcome to the **CV Analyzer Project**! In this comprehensive tutorial, you'll build an intelligent CV analysis system that processes candidate resumes and matches them to predefined job roles.\n",
    "\n",
    "## üß† Manual CV Analysis Challenge\n",
    "\n",
    "Before we dive into automation, let's experience what HR professionals do every day.\n",
    "\n",
    "**üìù Your First Task**: Explore the CVs in the `data/cvs` folder and manually extract key information from each CV. For each CV, try to identify:\n",
    "\n",
    "1. **Personal Details**: Name, contact information, location\n",
    "2. **Key Skills**: Technical skills, soft skills, tools\n",
    "3. **Experience**: Years of experience, previous roles, responsibilities\n",
    "4. **Education**: Degrees, institutions, graduation years\n",
    "5. **Role Fit**: Which job role would be the best match? Developer, QA, or DevOps?\n",
    "\n",
    "**üîç Instructions**:\n",
    "1. Open the text files in the `data/cvs` folder\n",
    "2. For each CV, create a summary with the information above\n",
    "3. Estimate how suitable the candidate is for each role (score 1-10)\n",
    "4. Track how long it takes you to process each CV\n",
    "\n",
    "**üìù Manual Analysis Template**:\n",
    "```\n",
    "Candidate Name: \n",
    "Contact Info: \n",
    "Location: \n",
    "Key Skills:\n",
    "Years of Experience:\n",
    "Previous Positions:\n",
    "Education:\n",
    "Best Role Match:\n",
    "Fit Score (1-10):\n",
    "Time spent analyzing: ___ minutes\n",
    "```\n",
    "\n",
    "**üí≠ Reflection**: After analyzing 2-3 CVs, consider:\n",
    "- How long did this take you?\n",
    "- How consistent were your evaluations?\n",
    "- How confident are you in your role recommendations?\n",
    "- Could you maintain this quality for dozens of CVs?\n",
    "\n",
    "## ü§ñ Finding it Difficult? Let's Automate!\n",
    "\n",
    "If you found the manual CV analysis:\n",
    "- Time-consuming (taking 5-10 minutes per CV)\n",
    "- Prone to inconsistency and human error\n",
    "- Difficult to scale when processing dozens of applications\n",
    "- Challenging to standardize across different HR team members\n",
    "\n",
    "... then you're experiencing the exact challenges that HR professionals face every day!\n",
    "\n",
    "Our automated solution will:\n",
    "- Process text-based CVs in seconds\n",
    "- Extract key entities with high accuracy\n",
    "- Match candidates to job roles systematically\n",
    "- Generate consistent reports for hiring decisions\n",
    "\n",
    "**Skills Focus**:\n",
    "- Entity extraction using prompt engineering\n",
    "- Text classification with OpenAI\n",
    "- Basic candidate scoring\n",
    "- Structured output generation\n",
    "\n",
    "**Input**: Text files (.txt) containing candidate CVs  \n",
    "**Output**: Candidate profiles with role recommendations\n",
    "\n",
    "## üìù What You'll Learn\n",
    "\n",
    "1. **Prompt Engineering**: Design effective prompts for entity extraction\n",
    "2. **Text Classification**: Categorize candidates by role fit\n",
    "3. **Structured Data**: Convert unstructured CV text into organized profiles\n",
    "4. **HR Decision Making**: Generate actionable hiring recommendations\n",
    "\n",
    "## üîç Project Workflow\n",
    "\n",
    "1. **Load Text CVs** from the data folder\n",
    "2. **Extract Entities** (name, skills, experience, education)\n",
    "3. **Calculate Role Fit** scores for each position\n",
    "4. **Generate Reports** with hiring recommendations\n",
    "5. **Batch Process** multiple candidates efficiently"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b85ff5ff",
   "metadata": {},
   "source": [
    "## Let's Start Building Our CV Analysis System\n",
    "\n",
    "Now that you understand the challenges of manual CV analysis, let's build an automated solution. Our system will:\n",
    "\n",
    "1. Read CV text files from the `data/cvs` folder \n",
    "2. Use AI to extract structured information\n",
    "3. Match candidates to appropriate job roles\n",
    "4. Generate comprehensive HR reports\n",
    "\n",
    "This approach will save hours of manual work and provide consistent results across all candidates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc791e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Install Required Libraries\n",
    "\n",
    "# Basic libraries for Project 1\n",
    "!pip install langchain openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7560dd39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: You might need to restart your kernel after installation\n",
    "import sys\n",
    "print(\"Python version:\", sys.version)\n",
    "print(\"\\n‚úÖ Installation complete! Restart kernel if needed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f5b7c13",
   "metadata": {},
   "source": [
    "## Setup Environment and Import Libraries üîß\n",
    "\n",
    "First, we'll set up our environment and import the necessary libraries for the CV analysis:\n",
    "\n",
    "- **langchain**: For working with language models\n",
    "- **openai**: The OpenAI API client\n",
    "- **re**: For regular expressions (pattern matching)\n",
    "- **os**: For file handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606133e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Import Libraries and Setup Environment\n",
    "\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "from typing import Dict, List, Optional\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from enum import Enum\n",
    "\n",
    "# For AI/LLM operations\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "# Read API key from config.txt file\n",
    "config_file = Path('config.txt')\n",
    "openai_api_key = None\n",
    "\n",
    "if config_file.exists():\n",
    "    with open(config_file, 'r') as f:\n",
    "        for line in f:\n",
    "            if line.startswith('OPENAI_API_KEY='):\n",
    "                openai_api_key = line.strip().split('=')[1]\n",
    "                break\n",
    "\n",
    "if openai_api_key:\n",
    "    print(\"‚úÖ OpenAI API key loaded successfully from config.txt!\")\n",
    "    print(f\"üîë API key starts with: {openai_api_key[:8]}...\")\n",
    "else:\n",
    "    print(\"‚ùå OpenAI API key not found!\")\n",
    "    print(\"Please make sure config.txt file exists with your OPENAI_API_KEY\")\n",
    "    print(\"Example content: OPENAI_API_KEY=sk-your-key-here\")\n",
    "\n",
    "print(\"\\nüìö All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c053abb4",
   "metadata": {},
   "source": [
    "### Define Job Roles and Requirements üìã\n",
    "\n",
    "Before we can analyze CVs, we need to define the job roles and their requirements. This will be used later for candidate matching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c87e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define job roles and evaluation criteria\n",
    "\n",
    "class ExperienceLevel(Enum):\n",
    "    JUNIOR = \"Junior (0-2 years)\"\n",
    "    MID = \"Mid-level (2-5 years)\"\n",
    "    SENIOR = \"Senior (5+ years)\"\n",
    "    LEAD = \"Lead/Principal (8+ years)\"\n",
    "\n",
    "class JobRole(Enum):\n",
    "    DEVELOPER = \"Software Developer\"\n",
    "    QA_ENGINEER = \"QA Engineer\"\n",
    "    DEVOPS_ENGINEER = \"DevOps Engineer\"\n",
    "\n",
    "class RoleRequirements:\n",
    "    \"\"\"Define requirements for each job role\"\"\"\n",
    "    def __init__(self, role, required_skills, preferred_skills, \n",
    "                min_experience, education_requirements, soft_skills):\n",
    "        self.role = role\n",
    "        self.required_skills = required_skills\n",
    "        self.preferred_skills = preferred_skills\n",
    "        self.min_experience = min_experience\n",
    "        self.education_requirements = education_requirements\n",
    "        self.soft_skills = soft_skills\n",
    "    \n",
    "# Define role requirements\n",
    "ROLE_DEFINITIONS = {\n",
    "    JobRole.DEVELOPER: RoleRequirements(\n",
    "        role=JobRole.DEVELOPER,\n",
    "        required_skills=[\"Python\", \"JavaScript\", \"SQL\", \"Git\", \"REST APIs\"],\n",
    "        preferred_skills=[\"React\", \"Node.js\", \"Django\", \"AWS\", \"Docker\"],\n",
    "        min_experience=2,\n",
    "        education_requirements=[\"Computer Science\", \"Software Engineering\", \"Information Technology\"],\n",
    "        soft_skills=[\"Problem-solving\", \"Teamwork\", \"Communication\", \"Adaptability\"]\n",
    "    ),\n",
    "    \n",
    "    JobRole.QA_ENGINEER: RoleRequirements(\n",
    "        role=JobRole.QA_ENGINEER,\n",
    "        required_skills=[\"Test Automation\", \"Selenium\", \"API Testing\", \"SQL\", \"Bug Tracking\"],\n",
    "        preferred_skills=[\"Cypress\", \"TestNG\", \"Postman\", \"JIRA\", \"Performance Testing\"],\n",
    "        min_experience=1,\n",
    "        education_requirements=[\"Computer Science\", \"Engineering\", \"Information Technology\"],\n",
    "        soft_skills=[\"Attention to Detail\", \"Analytical Thinking\", \"Documentation\", \"Patience\"]\n",
    "    ),\n",
    "    \n",
    "    JobRole.DEVOPS_ENGINEER: RoleRequirements(\n",
    "        role=JobRole.DEVOPS_ENGINEER,\n",
    "        required_skills=[\"AWS\", \"Docker\", \"Kubernetes\", \"CI/CD\", \"Linux\", \"Monitoring\"],\n",
    "        preferred_skills=[\"Terraform\", \"Jenkins\", \"Ansible\", \"Prometheus\", \"ELK Stack\"],\n",
    "        min_experience=3,\n",
    "        education_requirements=[\"Computer Science\", \"Systems Administration\", \"Engineering\"],\n",
    "        soft_skills=[\"System Thinking\", \"Troubleshooting\", \"Collaboration\", \"Continuous Learning\"]\n",
    "    )\n",
    "}\n",
    "\n",
    "print(\"üéØ Job roles and requirements defined!\")\n",
    "print(\"\\nüìã Available Positions:\")\n",
    "for role, req in ROLE_DEFINITIONS.items():\n",
    "    print(f\"- {role.value}: {len(req.required_skills)} core skills, {req.min_experience}+ years experience\")\n",
    "\n",
    "print(\"\\n‚úÖ HR workflow configuration ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "551cd0b8",
   "metadata": {},
   "source": [
    "## Create Project Directories üìÅ\n",
    "\n",
    "Let's create the necessary directories for our project:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a58e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create project directory structure\n",
    "def create_project_structure():\n",
    "    \"\"\"\n",
    "    Create folder structure for HR workflow simulation.\n",
    "    \"\"\"\n",
    "    folders = [\n",
    "        'output/reports',      # Generated reports\n",
    "        'output/matches',      # Role matching results\n",
    "        'data/job_roles',      # Job role definitions\n",
    "    ]\n",
    "    \n",
    "    print(\"üìÅ Creating project directory structure...\")\n",
    "    for folder in folders:\n",
    "        try:\n",
    "            os.makedirs(folder, exist_ok=True)\n",
    "            print(f\"‚úÖ Created: {folder}\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error creating {folder}: {str(e)}\")\n",
    "    \n",
    "    print(\"\\nüè¢ Project Structure:\")\n",
    "    print(\"‚îú‚îÄ‚îÄ data/\")\n",
    "    print(\"‚îÇ   ‚îú‚îÄ‚îÄ cvs/         # CV files for analysis\")\n",
    "    print(\"‚îÇ   ‚îî‚îÄ‚îÄ job_roles/   # Role definitions\")\n",
    "    print(\"‚îî‚îÄ‚îÄ output/\")\n",
    "    print(\"    ‚îú‚îÄ‚îÄ reports/     # HR reports\")\n",
    "    print(\"    ‚îî‚îÄ‚îÄ matches/     # Role matching\")\n",
    "    print(\"\\nüìù Note: We'll use CVs from the data/cvs folder for analysis\")\n",
    "\n",
    "create_project_structure()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136a1eab",
   "metadata": {},
   "source": [
    "## Setup LLM and Prompt Templates ü§ñ\n",
    "\n",
    "Now we'll initialize our language model and create prompt templates for entity extraction and role classification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6445bc30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize OpenAI LLM\n",
    "if openai_api_key:\n",
    "    llm = OpenAI(\n",
    "        temperature=0,  # Low temperature for consistent, factual responses\n",
    "        openai_api_key=openai_api_key,\n",
    "        model_name=\"gpt-3.5-turbo-instruct\"  # Cost-effective model\n",
    "    )\n",
    "    print(\"ü§ñ OpenAI LLM initialized successfully!\")\n",
    "else:\n",
    "    print(\"‚ùå Cannot initialize LLM without API key\")\n",
    "    llm = None\n",
    "\n",
    "# Entity Extraction Prompt Template\n",
    "entity_extraction_prompt = PromptTemplate(\n",
    "    input_variables=[\"cv_text\"],\n",
    "    template=\"\"\"\n",
    "    You are an expert HR assistant analyzing a candidate's CV. Extract the following information:\n",
    "    \n",
    "    CV Text:\n",
    "    {cv_text}\n",
    "    \n",
    "    Extract and return ONLY the following information in JSON format:\n",
    "    {{\n",
    "        \"name\": \"Candidate's full name\",\n",
    "        \"email\": \"Email address\",\n",
    "        \"phone\": \"Phone number\", \n",
    "        \"location\": \"City, Country\",\n",
    "        \"skills\": [\"List of all technical and soft skills\"],\n",
    "        \"experience\": [\n",
    "            {{\n",
    "                \"company\": \"Company name\",\n",
    "                \"position\": \"Job title\",\n",
    "                \"duration\": \"Employment period\",\n",
    "                \"responsibilities\": \"Key responsibilities\"\n",
    "            }}\n",
    "        ],\n",
    "        \"education\": [\n",
    "            {{\n",
    "                \"degree\": \"Degree name\",\n",
    "                \"institution\": \"University/School name\", \n",
    "                \"year\": \"Graduation year\",\n",
    "                \"field\": \"Field of study\"\n",
    "            }}\n",
    "        ],\n",
    "        \"total_experience_years\": \"Number of years of relevant work experience\"\n",
    "    }}\n",
    "    \n",
    "    Be thorough but concise. Extract only factual information present in the CV.\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "# Role Classification Prompt Template\n",
    "role_classification_prompt = PromptTemplate(\n",
    "    input_variables=[\"candidate_profile\", \"role_requirements\"],\n",
    "    template=\"\"\"\n",
    "    You are an HR specialist evaluating a candidate for a specific role.\n",
    "    \n",
    "    Candidate Profile:\n",
    "    {candidate_profile}\n",
    "    \n",
    "    Role Requirements:\n",
    "    {role_requirements}\n",
    "    \n",
    "    Analyze the candidate's fit for this role and return a JSON response:\n",
    "    {{\n",
    "        \"role_fit_score\": \"Score from 0-100 based on skills and experience match\",\n",
    "        \"matching_skills\": [\"List of candidate skills that match role requirements\"],\n",
    "        \"missing_skills\": [\"List of required skills the candidate lacks\"],\n",
    "        \"experience_level\": \"Junior/Mid-level/Senior based on years and complexity\",\n",
    "        \"strengths\": [\"Top 3 strengths for this role\"],\n",
    "        \"concerns\": [\"Top 3 concerns or gaps\"],\n",
    "        \"recommendation\": \"Strong Fit/Good Fit/Moderate Fit/Poor Fit\",\n",
    "        \"justification\": \"Brief explanation of the recommendation\"\n",
    "    }}\n",
    "    \n",
    "    Be objective and consider both technical skills and experience relevance.\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Prompt templates created!\")\n",
    "print(\"üìã Templates ready for:\")\n",
    "print(\"- Entity extraction from text CVs\")\n",
    "print(\"- Role-based candidate classification\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ddbd732",
   "metadata": {},
   "source": [
    "## Implement Basic CV Analyzer üîç\n",
    "\n",
    "Let's implement the core functionality of our CV Analyzer for Project 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6a8f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project 1: Core Functions for Text CV Processing\n",
    "\n",
    "class Project1_BasicExtractor:\n",
    "    \"\"\"\n",
    "    Basic CV analyzer for text-based documents (Project 1)\n",
    "    Focus: Entity extraction and role classification\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.results = []\n",
    "        self.processed_count = 0\n",
    "        print(\"üü¢ Project 1: Basic Entity Extractor initialized!\")\n",
    "    \n",
    "    def load_text_cv(self, file_path: str) -> str:\n",
    "        \"\"\"\n",
    "        Load text content from a .txt CV file.\n",
    "        \n",
    "        Args:\n",
    "            file_path (str): Path to the text CV file\n",
    "            \n",
    "        Returns:\n",
    "            str: CV content as text\n",
    "        \"\"\"\n",
    "        try:\n",
    "            with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                content = file.read().strip()\n",
    "                print(f\"üìù Loaded CV: {os.path.basename(file_path)} ({len(content)} characters)\")\n",
    "                return content\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error loading {file_path}: {str(e)}\")\n",
    "            return \"\"\n",
    "    \n",
    "    def extract_entities(self, cv_text: str) -> dict:\n",
    "        \"\"\"\n",
    "        Extract structured entities from CV text using AI.\n",
    "        \n",
    "        Args:\n",
    "            cv_text (str): Raw CV content\n",
    "            \n",
    "        Returns:\n",
    "            dict: Extracted entities\n",
    "        \"\"\"\n",
    "        if not llm:\n",
    "            return {\"error\": \"LLM not initialized\"}\n",
    "        \n",
    "        try:\n",
    "            print(\"üîÑ Extracting entities from CV...\")\n",
    "            chain = LLMChain(llm=llm, prompt=entity_extraction_prompt)\n",
    "            result = chain.run(cv_text=cv_text)\n",
    "            \n",
    "            # Parse JSON response\n",
    "            try:\n",
    "                entities = json.loads(result.strip())\n",
    "                print(\"‚úÖ Entities extracted successfully\")\n",
    "                return entities\n",
    "            except json.JSONDecodeError:\n",
    "                print(\"‚ö†Ô∏è JSON parsing failed, using raw response\")\n",
    "                return {\"raw_response\": result.strip()}\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error extracting entities: {str(e)}\")\n",
    "            return {\"error\": str(e)}\n",
    "    \n",
    "    def classify_for_role(self, candidate_profile: dict, target_role: JobRole) -> dict:\n",
    "        \"\"\"\n",
    "        Classify candidate fit for a specific role.\n",
    "        \n",
    "        Args:\n",
    "            candidate_profile (dict): Extracted candidate information\n",
    "            target_role (JobRole): Role to evaluate against\n",
    "            \n",
    "        Returns:\n",
    "            dict: Role fit analysis\n",
    "        \"\"\"\n",
    "        if not llm:\n",
    "            return {\"error\": \"LLM not initialized\"}\n",
    "        \n",
    "        role_req = ROLE_DEFINITIONS[target_role]\n",
    "        \n",
    "        try:\n",
    "            print(f\"üéØ Analyzing fit for {target_role.value}...\")\n",
    "            \n",
    "            # Prepare role requirements summary\n",
    "            requirements_summary = {\n",
    "                \"role\": target_role.value,\n",
    "                \"required_skills\": role_req.required_skills,\n",
    "                \"preferred_skills\": role_req.preferred_skills,\n",
    "                \"min_experience\": role_req.min_experience,\n",
    "                \"education\": role_req.education_requirements,\n",
    "                \"soft_skills\": role_req.soft_skills\n",
    "            }\n",
    "            \n",
    "            chain = LLMChain(llm=llm, prompt=role_classification_prompt)\n",
    "            result = chain.run(\n",
    "                candidate_profile=json.dumps(candidate_profile, indent=2),\n",
    "                role_requirements=json.dumps(requirements_summary, indent=2)\n",
    "            )\n",
    "            \n",
    "            # Parse JSON response\n",
    "            try:\n",
    "                classification = json.loads(result.strip())\n",
    "                classification[\"target_role\"] = target_role.value\n",
    "                print(f\"‚úÖ Role analysis completed - {classification.get('recommendation', 'Unknown')} fit\")\n",
    "                return classification\n",
    "            except json.JSONDecodeError:\n",
    "                print(\"‚ö†Ô∏è JSON parsing failed for classification\")\n",
    "                return {\"target_role\": target_role.value, \"raw_response\": result.strip()}\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error in role classification: {str(e)}\")\n",
    "            return {\"target_role\": target_role.value, \"error\": str(e)}\n",
    "    \n",
    "    def process_single_cv(self, cv_file_path: str) -> dict:\n",
    "        \"\"\"\n",
    "        Complete processing pipeline for a single CV.\n",
    "        \n",
    "        Args:\n",
    "            cv_file_path (str): Path to CV text file\n",
    "            \n",
    "        Returns:\n",
    "            dict: Complete candidate analysis\n",
    "        \"\"\"\n",
    "        print(f\"\\nüöÄ Processing CV: {os.path.basename(cv_file_path)}\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        # Step 1: Load CV text\n",
    "        cv_text = self.load_text_cv(cv_file_path)\n",
    "        if not cv_text:\n",
    "            return {\"error\": \"Failed to load CV\"}\n",
    "        \n",
    "        # Step 2: Extract entities\n",
    "        entities = self.extract_entities(cv_text)\n",
    "        if \"error\" in entities:\n",
    "            return entities\n",
    "        \n",
    "        # Step 3: Classify for all roles\n",
    "        role_analyses = {}\n",
    "        for role in JobRole:\n",
    "            analysis = self.classify_for_role(entities, role)\n",
    "            role_analyses[role.value] = analysis\n",
    "        \n",
    "        # Step 4: Determine best fit role\n",
    "        best_role = self.find_best_role_match(role_analyses)\n",
    "        \n",
    "        # Compile complete profile\n",
    "        complete_profile = {\n",
    "            \"candidate_info\": entities,\n",
    "            \"role_analyses\": role_analyses,\n",
    "            \"best_role_match\": best_role,\n",
    "            \"processed_at\": datetime.now().isoformat(),\n",
    "            \"source_file\": os.path.basename(cv_file_path)\n",
    "        }\n",
    "        \n",
    "        self.processed_count += 1\n",
    "        self.results.append(complete_profile)\n",
    "        \n",
    "        print(f\"‚úÖ CV processing completed! Best fit: {best_role['role']} ({best_role['score']}% match)\")\n",
    "        return complete_profile\n",
    "    \n",
    "    def find_best_role_match(self, role_analyses: dict) -> dict:\n",
    "        \"\"\"\n",
    "        Find the role with the highest fit score.\n",
    "        \n",
    "        Args:\n",
    "            role_analyses (dict): All role analysis results\n",
    "            \n",
    "        Returns:\n",
    "            dict: Best matching role information\n",
    "        \"\"\"\n",
    "        best_role = {\"role\": \"Unknown\", \"score\": 0, \"recommendation\": \"No match\"}\n",
    "        \n",
    "        for role_name, analysis in role_analyses.items():\n",
    "            if \"role_fit_score\" in analysis:\n",
    "                try:\n",
    "                    score = float(analysis[\"role_fit_score\"])\n",
    "                    if score > best_role[\"score\"]:\n",
    "                        best_role = {\n",
    "                            \"role\": role_name,\n",
    "                            \"score\": score,\n",
    "                            \"recommendation\": analysis.get(\"recommendation\", \"Unknown\")\n",
    "                        }\n",
    "                except (ValueError, TypeError):\n",
    "                    continue\n",
    "        \n",
    "        return best_role\n",
    "    \n",
    "    def save_results(self, output_dir: str = \"output/reports\") -> None:\n",
    "        \"\"\"\n",
    "        Save analysis results to JSON files.\n",
    "        \n",
    "        Args:\n",
    "            output_dir (str): Directory to save results\n",
    "        \"\"\"\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        \n",
    "        for result in self.results:\n",
    "            candidate_name = result[\"candidate_info\"].get(\"name\", \"unknown\").replace(\" \", \"_\").lower()\n",
    "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "            filename = f\"{candidate_name}_{timestamp}.json\"\n",
    "            filepath = os.path.join(output_dir, filename)\n",
    "            \n",
    "            try:\n",
    "                with open(filepath, 'w', encoding='utf-8') as f:\n",
    "                    json.dump(result, f, indent=2)\n",
    "                print(f\"üíæ Saved report: {filename}\")\n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Error saving report: {str(e)}\")\n",
    "\n",
    "# Initialize Project 1 extractor\n",
    "project1_extractor = Project1_BasicExtractor()\n",
    "print(\"\\nüéØ Project 1 ready for text CV processing!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e18a3aa2",
   "metadata": {},
   "source": [
    "## Analyzing CV Files in the Data Folder üìÑ\n",
    "\n",
    "We'll analyze the CV files you manually reviewed in the `data/cvs` folder. Let's see what files are available:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161ab32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List the CV files for analysis\n",
    "def list_cv_files():\n",
    "    \"\"\"\n",
    "    List the CV files in the data/cvs folder that were manually analyzed.\n",
    "    \"\"\"\n",
    "    cv_dir = os.path.join('data', 'cvs')\n",
    "    \n",
    "    # Ensure the directory exists\n",
    "    if not os.path.exists(cv_dir):\n",
    "        print(f\"‚ö†Ô∏è Data directory {cv_dir} does not exist!\")\n",
    "        print(\"Creating the directory now...\")\n",
    "        os.makedirs(cv_dir, exist_ok=True)\n",
    "    \n",
    "    # List CV files with various extensions\n",
    "    extensions = ['.txt', '.docx', '.pdf', '.doc']\n",
    "    cv_files = []\n",
    "    \n",
    "    for ext in extensions:\n",
    "        files = [f for f in os.listdir(cv_dir) if f.endswith(ext)]\n",
    "        cv_files.extend(files)\n",
    "    \n",
    "    # Display results\n",
    "    if cv_files:\n",
    "        print(f\"üìä Found {len(cv_files)} CV files that you analyzed manually\")\n",
    "        print(\"\\nCV files available for automated analysis:\")\n",
    "        for i, file in enumerate(cv_files, 1):\n",
    "            print(f\"{i}. {file}\")\n",
    "        \n",
    "        # Show file type statistics\n",
    "        txt_files = len([f for f in cv_files if f.endswith('.txt')])\n",
    "        other_files = len(cv_files) - txt_files\n",
    "        print(f\"\\nüìù File type breakdown:\")\n",
    "        print(f\"   - Text files (.txt): {txt_files} (will be processed in Project 1)\")\n",
    "        if other_files > 0:\n",
    "            print(f\"   - Other formats: {other_files} (will need Project 2 for processing)\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è No CV files found in {cv_dir}/\")\n",
    "        print(\"Please add some sample CV files (in .txt format) to this folder to continue.\")\n",
    "    \n",
    "    return cv_files\n",
    "\n",
    "# List the CV files to be analyzed\n",
    "cv_files = list_cv_files()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a532acbe",
   "metadata": {},
   "source": [
    "## Process and Analyze CVs üöÄ\n",
    "\n",
    "Now, let's run our CV analyzer on the sample CVs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06a79f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process CVs from data folder\n",
    "\n",
    "def process_cv_batch():\n",
    "    \"\"\"\n",
    "    Process CVs from the data/cvs folder.\n",
    "    \"\"\"\n",
    "    print(\"üöÄ Starting CV Analysis with Project 1\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Check if API key is available\n",
    "    if not openai_api_key:\n",
    "        print(\"‚ùå OpenAI API key not configured\")\n",
    "        print(\"Please set up your config.txt file with OPENAI_API_KEY\")\n",
    "        return\n",
    "    \n",
    "    # Get CV files from data folder\n",
    "    cv_dir = os.path.join('data', 'cvs')\n",
    "    cv_files = []\n",
    "    \n",
    "    if os.path.exists(cv_dir):\n",
    "        for file in os.listdir(cv_dir):\n",
    "            # For Project 1, we'll focus on text files, but note which files we're skipping\n",
    "            if file.endswith('.txt'):\n",
    "                cv_files.append(file)\n",
    "            elif file.endswith(('.docx', '.doc', '.pdf')):\n",
    "                print(f\"‚ö†Ô∏è Skipping {file} - Project 1 supports only .txt files\")\n",
    "                print(\"   (Use Project 2 for multi-format document processing)\")\n",
    "    \n",
    "    if not cv_files:\n",
    "        print(\"‚ùå No text CV files found in data/cvs/\")\n",
    "        print(\"The system expects text (.txt) CV files in this folder.\")\n",
    "        print(\"Please add text CV files to continue.\")\n",
    "        return\n",
    "    \n",
    "    # Display processing information\n",
    "    print(f\"üìÑ Processing {len(cv_files)} CV files from the data folder\")\n",
    "    \n",
    "    print(f\"\\nüìÑ Ready to process {len(cv_files)} CV files\")\n",
    "    \n",
    "    # Process each CV\n",
    "    for cv_file in cv_files:\n",
    "        cv_path = os.path.join(cv_dir, cv_file)\n",
    "        result = project1_extractor.process_single_cv(cv_path)\n",
    "        \n",
    "        if \"error\" not in result:\n",
    "            print(f\"\\nüìä Results for {cv_file}:\")\n",
    "            print(f\"- Name: {result['candidate_info'].get('name', 'Not found')}\")\n",
    "            print(f\"- Best Role: {result['best_role_match']['role']} ({result['best_role_match']['score']}% fit)\")\n",
    "            print(f\"- Skills Count: {len(result['candidate_info'].get('skills', []))}\")\n",
    "            print(f\"- Experience: {result['candidate_info'].get('total_experience_years', 'Unknown')} years\")\n",
    "    \n",
    "    # Save results to files\n",
    "    project1_extractor.save_results()\n",
    "    \n",
    "    print(f\"\\n‚úÖ CV Analysis completed! Processed {project1_extractor.processed_count} CVs\")\n",
    "    print(\"   HR summary report will be generated next\")\n",
    "\n",
    "# Run the analysis on CVs in the data folder\n",
    "if cv_files:  # Only run if CV files were found\n",
    "    process_cv_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051f8dff",
   "metadata": {},
   "source": [
    "## Generate HR Summary Report üìä\n",
    "\n",
    "Now that we've processed all the CVs from the data folder, let's create an HR summary report that shows the best candidates for each role:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ec5228",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate HR Summary Report\n",
    "\n",
    "def generate_hr_summary():\n",
    "    \"\"\"\n",
    "    Generate an HR summary report showing best candidates for each role.\n",
    "    \"\"\"\n",
    "    if not project1_extractor.results:\n",
    "        print(\"‚ùå No results to summarize. Process some CVs first.\")\n",
    "        return\n",
    "    \n",
    "    print(\"\\nüìä HR SUMMARY REPORT\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Total Candidates Processed: {len(project1_extractor.results)}\")\n",
    "    print(f\"Processing Date: {datetime.now().strftime('%Y-%m-%d %H:%M')}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Organize candidates by best-fit role\n",
    "    candidates_by_role = {}\n",
    "    for result in project1_extractor.results:\n",
    "        best_role = result[\"best_role_match\"][\"role\"]\n",
    "        if best_role not in candidates_by_role:\n",
    "            candidates_by_role[best_role] = []\n",
    "        \n",
    "        candidates_by_role[best_role].append({\n",
    "            \"name\": result[\"candidate_info\"].get(\"name\", \"Unknown\"),\n",
    "            \"score\": result[\"best_role_match\"][\"score\"],\n",
    "            \"recommendation\": result[\"best_role_match\"][\"recommendation\"],\n",
    "            \"experience\": result[\"candidate_info\"].get(\"total_experience_years\", \"Unknown\"),\n",
    "            \"file\": result[\"source_file\"]\n",
    "        })\n",
    "    \n",
    "    # Sort candidates by score for each role\n",
    "    for role, candidates in candidates_by_role.items():\n",
    "        candidates.sort(key=lambda x: x[\"score\"], reverse=True)\n",
    "        \n",
    "        print(f\"\\nüéØ Role: {role}\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        for i, candidate in enumerate(candidates, 1):\n",
    "            print(f\"{i}. {candidate['name']}\")\n",
    "            print(f\"   Score: {candidate['score']}% | Recommendation: {candidate['recommendation']}\")\n",
    "            print(f\"   Experience: {candidate['experience']} years | Source: {candidate['file']}\")\n",
    "        \n",
    "        if not candidates:\n",
    "            print(\"No candidates matched this role.\")\n",
    "    \n",
    "    # Generate recommendations\n",
    "    print(\"\\nüîç HR RECOMMENDATIONS\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    for role, candidates in candidates_by_role.items():\n",
    "        strong_candidates = [c for c in candidates if c[\"score\"] >= 75]\n",
    "        \n",
    "        if strong_candidates:\n",
    "            top_candidate = strong_candidates[0]\n",
    "            print(f\"‚úÖ For {role}: Recommend interviewing {top_candidate['name']} ({top_candidate['score']}% match)\")\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è For {role}: No strong candidates found. Consider expanding search.\")\n",
    "    \n",
    "    # Save summary report\n",
    "    try:\n",
    "        os.makedirs('output/reports', exist_ok=True)\n",
    "        report_file = f\"output/reports/hr_summary_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt\"\n",
    "        \n",
    "        with open(report_file, 'w', encoding='utf-8') as f:\n",
    "            f.write(\"HR SUMMARY REPORT\\n\")\n",
    "            f.write(\"=\" * 60 + \"\\n\")\n",
    "            f.write(f\"Total Candidates Processed: {len(project1_extractor.results)}\\n\")\n",
    "            f.write(f\"Processing Date: {datetime.now().strftime('%Y-%m-%d %H:%M')}\\n\")\n",
    "            f.write(\"=\" * 60 + \"\\n\\n\")\n",
    "            \n",
    "            for role, candidates in candidates_by_role.items():\n",
    "                f.write(f\"Role: {role}\\n\")\n",
    "                f.write(\"-\" * 40 + \"\\n\")\n",
    "                \n",
    "                for i, candidate in enumerate(candidates, 1):\n",
    "                    f.write(f\"{i}. {candidate['name']}\\n\")\n",
    "                    f.write(f\"   Score: {candidate['score']}% | Recommendation: {candidate['recommendation']}\\n\")\n",
    "                    f.write(f\"   Experience: {candidate['experience']} years | Source: {candidate['file']}\\n\\n\")\n",
    "            \n",
    "            f.write(\"\\nHR RECOMMENDATIONS\\n\")\n",
    "            f.write(\"-\" * 40 + \"\\n\")\n",
    "            \n",
    "            for role, candidates in candidates_by_role.items():\n",
    "                strong_candidates = [c for c in candidates if c[\"score\"] >= 75]\n",
    "                \n",
    "                if strong_candidates:\n",
    "                    top_candidate = strong_candidates[0]\n",
    "                    f.write(f\"For {role}: Recommend interviewing {top_candidate['name']} ({top_candidate['score']}% match)\\n\")\n",
    "                else:\n",
    "                    f.write(f\"For {role}: No strong candidates found. Consider expanding search.\\n\")\n",
    "        \n",
    "        print(f\"\\n‚úÖ Summary report saved to {report_file}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error saving summary report: {str(e)}\")\n",
    "\n",
    "# Generate the HR summary\n",
    "generate_hr_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "703cfb7a",
   "metadata": {},
   "source": [
    "## üéâ Conclusion\n",
    "\n",
    "In Project 1, you've learned how to:\n",
    "\n",
    "‚úÖ **Extract structured information** from plain text CVs using AI  \n",
    "‚úÖ **Classify candidates** against predefined job roles  \n",
    "‚úÖ **Calculate role fit scores** based on skills and experience  \n",
    "‚úÖ **Generate HR recommendations** for candidate selection  \n",
    "‚úÖ **Process multiple CVs** from a real data folder  \n",
    "\n",
    "This project demonstrates how to automate the tedious task of CV analysis that HR professionals typically do manually. By analyzing CVs from the data folder, we've shown how this solution can be applied to real-world HR workflows.\n",
    "\n",
    "In Project 2, we'll expand these capabilities to handle different document formats (PDF, Word, Excel) and generate more sophisticated outputs, making the system even more versatile for HR departments.\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "To use this system with your own CVs:\n",
    "1. Place your text CV files in the `data/cvs` folder\n",
    "2. Run this notebook to process them automatically\n",
    "3. Check the `output/reports` folder for detailed results"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
