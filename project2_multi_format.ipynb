{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9279f07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Install Required Libraries\n",
    "\n",
    "# Multi-format document processing libraries\n",
    "!pip install langchain openai PyPDF2 python-docx openpyxl pandas matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba1f96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: You might need to restart your kernel after installation\n",
    "import sys\n",
    "print(\"Python version:\", sys.version)\n",
    "print(\"\\nâœ… Installation complete! Restart kernel if needed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6c0e85",
   "metadata": {},
   "source": [
    "## Setup Environment and Import Libraries ðŸ”§\n",
    "\n",
    "Let's set up our environment and import the necessary libraries for multi-format document processing:\n",
    "\n",
    "- **langchain & openai**: For working with language models\n",
    "- **PyPDF2**: For processing PDF files\n",
    "- **python-docx**: For processing Word documents\n",
    "- **openpyxl**: For processing Excel files\n",
    "- **pandas**: For data manipulation and analysis\n",
    "- **matplotlib**: For visualization and reporting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6108ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Import Libraries and Setup Environment\n",
    "\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import io\n",
    "from typing import Dict, List, Optional, Union, Any\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from enum import Enum\n",
    "import base64\n",
    "\n",
    "# For AI/LLM operations (same as Project 1)\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "# For multi-format document processing\n",
    "import PyPDF2\n",
    "from docx import Document\n",
    "import pandas as pd\n",
    "import openpyxl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Read API key from config.txt file (same as Project 1)\n",
    "config_file = Path('config.txt')\n",
    "openai_api_key = None\n",
    "\n",
    "if config_file.exists():\n",
    "    with open(config_file, 'r') as f:\n",
    "        for line in f:\n",
    "            if line.startswith('OPENAI_API_KEY='):\n",
    "                openai_api_key = line.strip().split('=')[1]\n",
    "                break\n",
    "\n",
    "if openai_api_key:\n",
    "    print(\"âœ… OpenAI API key loaded successfully from config.txt!\")\n",
    "    print(f\"ðŸ”‘ API key starts with: {openai_api_key[:8]}...\")\n",
    "else:\n",
    "    print(\"âŒ OpenAI API key not found!\")\n",
    "    print(\"Please make sure config.txt file exists with your OPENAI_API_KEY\")\n",
    "    print(\"Example content: OPENAI_API_KEY=sk-your-key-here\")\n",
    "\n",
    "print(\"\\nðŸ“š All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c917a1d",
   "metadata": {},
   "source": [
    "## Define the Multi-Format Document Processor ðŸ“‹\n",
    "\n",
    "Now we'll implement a document processor that can handle various file formats:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5cef2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-Format Document Processor\n",
    "\n",
    "class DocumentFormat(Enum):\n",
    "    \"\"\"Supported document formats\"\"\"\n",
    "    TEXT = \"text\"\n",
    "    PDF = \"pdf\"\n",
    "    WORD = \"word\"\n",
    "    EXCEL = \"excel\"\n",
    "    UNKNOWN = \"unknown\"\n",
    "\n",
    "class MultiFormatDocumentProcessor:\n",
    "    \"\"\"\n",
    "    Handles document processing for multiple file formats\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.supported_extensions = {\n",
    "            \".txt\": DocumentFormat.TEXT,\n",
    "            \".pdf\": DocumentFormat.PDF,\n",
    "            \".docx\": DocumentFormat.WORD,\n",
    "            \".doc\": DocumentFormat.WORD,\n",
    "            \".xlsx\": DocumentFormat.EXCEL,\n",
    "            \".xls\": DocumentFormat.EXCEL\n",
    "        }\n",
    "        print(\"ðŸ”„ Multi-format document processor initialized!\")\n",
    "        \n",
    "    def detect_format(self, file_path: str) -> DocumentFormat:\n",
    "        \"\"\"\n",
    "        Detects the document format based on file extension\n",
    "        \n",
    "        Args:\n",
    "            file_path (str): Path to the document file\n",
    "        \n",
    "        Returns:\n",
    "            DocumentFormat: Detected format enum\n",
    "        \"\"\"\n",
    "        _, ext = os.path.splitext(file_path.lower())\n",
    "        return self.supported_extensions.get(ext, DocumentFormat.UNKNOWN)\n",
    "    \n",
    "    def extract_text_from_file(self, file_path: str) -> str:\n",
    "        \"\"\"\n",
    "        Extracts text content from files of various formats\n",
    "        \n",
    "        Args:\n",
    "            file_path (str): Path to the document file\n",
    "        \n",
    "        Returns:\n",
    "            str: Extracted text content\n",
    "        \"\"\"\n",
    "        doc_format = self.detect_format(file_path)\n",
    "        \n",
    "        try:\n",
    "            if doc_format == DocumentFormat.TEXT:\n",
    "                return self._extract_from_text(file_path)\n",
    "            elif doc_format == DocumentFormat.PDF:\n",
    "                return self._extract_from_pdf(file_path)\n",
    "            elif doc_format == DocumentFormat.WORD:\n",
    "                return self._extract_from_word(file_path)\n",
    "            elif doc_format == DocumentFormat.EXCEL:\n",
    "                return self._extract_from_excel(file_path)\n",
    "            else:\n",
    "                print(f\"âŒ Unsupported file format: {os.path.basename(file_path)}\")\n",
    "                return \"\"\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Error extracting text from {os.path.basename(file_path)}: {str(e)}\")\n",
    "            return \"\"\n",
    "    \n",
    "    def _extract_from_text(self, file_path: str) -> str:\n",
    "        \"\"\"Extract text from .txt file\"\"\"\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            content = file.read()\n",
    "            print(f\"ðŸ“„ Extracted {len(content)} characters from text file\")\n",
    "            return content\n",
    "    \n",
    "    def _extract_from_pdf(self, file_path: str) -> str:\n",
    "        \"\"\"Extract text from PDF file\"\"\"\n",
    "        text = \"\"\n",
    "        with open(file_path, 'rb') as file:\n",
    "            pdf_reader = PyPDF2.PdfReader(file)\n",
    "            for page_num in range(len(pdf_reader.pages)):\n",
    "                page = pdf_reader.pages[page_num]\n",
    "                text += page.extract_text() + \"\\n\"\n",
    "        \n",
    "        print(f\"ðŸ“„ Extracted {len(text)} characters from PDF ({len(pdf_reader.pages)} pages)\")\n",
    "        return text\n",
    "    \n",
    "    def _extract_from_word(self, file_path: str) -> str:\n",
    "        \"\"\"Extract text from Word document\"\"\"\n",
    "        doc = Document(file_path)\n",
    "        text = \"\\n\".join([para.text for para in doc.paragraphs])\n",
    "        \n",
    "        print(f\"ðŸ“„ Extracted {len(text)} characters from Word document\")\n",
    "        return text\n",
    "    \n",
    "    def _extract_from_excel(self, file_path: str) -> str:\n",
    "        \"\"\"\n",
    "        Extract text from Excel file\n",
    "        This is a simplified approach - actual CV data in Excel may need \n",
    "        specific column mapping or structure understanding\n",
    "        \"\"\"\n",
    "        df = pd.read_excel(file_path)\n",
    "        # Convert DataFrame to string representation\n",
    "        text = df.to_string(index=False)\n",
    "        \n",
    "        print(f\"ðŸ“„ Extracted {len(text)} characters from Excel file\")\n",
    "        return text\n",
    "\n",
    "# Initialize the multi-format document processor\n",
    "doc_processor = MultiFormatDocumentProcessor()\n",
    "print(\"âœ… Multi-format document processor ready for CV analysis!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d616ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize OpenAI LLM (same as Project 1)\n",
    "if openai_api_key:\n",
    "    llm = OpenAI(\n",
    "        temperature=0,  # Low temperature for consistent, factual responses\n",
    "        openai_api_key=openai_api_key,\n",
    "        model_name=\"gpt-3.5-turbo-instruct\"  # Cost-effective model\n",
    "    )\n",
    "    print(\"ðŸ¤– OpenAI LLM initialized successfully!\")\n",
    "else:\n",
    "    print(\"âŒ Cannot initialize LLM without API key\")\n",
    "    llm = None\n",
    "\n",
    "# Enhanced Entity Extraction Prompt Template for multi-format documents\n",
    "enhanced_extraction_prompt = PromptTemplate(\n",
    "    input_variables=[\"cv_text\"],\n",
    "    template=\"\"\"\n",
    "    You are an expert HR assistant analyzing a candidate's CV extracted from various document formats. Extract the following information:\n",
    "    \n",
    "    CV Text:\n",
    "    {cv_text}\n",
    "    \n",
    "    Extract and return ONLY the following information in JSON format:\n",
    "    {{\n",
    "        \"name\": \"Candidate's full name\",\n",
    "        \"email\": \"Email address\",\n",
    "        \"phone\": \"Phone number\", \n",
    "        \"location\": \"City, Country\",\n",
    "        \"skills\": [\"List of all technical and soft skills\"],\n",
    "        \"experience\": [\n",
    "            {{\n",
    "                \"company\": \"Company name\",\n",
    "                \"position\": \"Job title\",\n",
    "                \"duration\": \"Employment period\",\n",
    "                \"responsibilities\": \"Key responsibilities\",\n",
    "                \"achievements\": \"Notable achievements\"\n",
    "            }}\n",
    "        ],\n",
    "        \"education\": [\n",
    "            {{\n",
    "                \"degree\": \"Degree name\",\n",
    "                \"institution\": \"University/School name\", \n",
    "                \"year\": \"Graduation year\",\n",
    "                \"field\": \"Field of study\"\n",
    "            }}\n",
    "        ],\n",
    "        \"certifications\": [\"List of professional certifications\"],\n",
    "        \"languages\": [\"Languages spoken\"],\n",
    "        \"total_experience_years\": \"Number of years of relevant work experience\"\n",
    "    }}\n",
    "    \n",
    "    Be thorough but concise. Extract only factual information present in the CV. If certain information is not available, use null or empty arrays as appropriate.\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "# Advanced Role Classification Prompt with weighted scoring\n",
    "advanced_classification_prompt = PromptTemplate(\n",
    "    input_variables=[\"candidate_profile\", \"role_requirements\", \"industry_context\"],\n",
    "    template=\"\"\"\n",
    "    You are an HR specialist with expertise in technical recruitment.\n",
    "    \n",
    "    Candidate Profile:\n",
    "    {candidate_profile}\n",
    "    \n",
    "    Role Requirements:\n",
    "    {role_requirements}\n",
    "    \n",
    "    Industry Context:\n",
    "    {industry_context}\n",
    "    \n",
    "    Analyze the candidate's fit for this role with weighted scoring and return a JSON response:\n",
    "    {{\n",
    "        \"role_fit_score\": \"Score from 0-100 based on skills and experience match\",\n",
    "        \"skill_match_percentage\": \"Percentage of required skills matched\",\n",
    "        \"experience_quality_score\": \"Score from 0-100 on relevance of experience\",\n",
    "        \"education_alignment\": \"Score from 0-100 on education fit\",\n",
    "        \"technical_proficiency\": \"Junior/Mid/Senior/Expert level assessment\",\n",
    "        \"matching_skills\": [\"List of candidate skills that match role requirements\"],\n",
    "        \"missing_skills\": [\"List of required skills the candidate lacks\"],\n",
    "        \"strengths\": [\"Top 3-5 strengths for this role\"],\n",
    "        \"growth_areas\": [\"Top 3 development areas\"],\n",
    "        \"recommendation\": \"Highly Recommended/Recommended/Consider/Not Recommended\",\n",
    "        \"interview_focus_areas\": [\"Suggested areas to explore in interview\"],\n",
    "        \"justification\": \"Brief explanation of the recommendation\"\n",
    "    }}\n",
    "    \n",
    "    Be objective and thorough in your assessment. Consider both technical skills and soft skills relevance.\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "print(\"âœ… Advanced prompt templates created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8b3522",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all CV files for multi-format processing\n",
    "def list_all_cv_files():\n",
    "    \"\"\"\n",
    "    List all CV files in the data/cvs folder regardless of format\n",
    "    \"\"\"\n",
    "    cv_dir = os.path.join('data', 'cvs')\n",
    "    \n",
    "    # Ensure the directory exists\n",
    "    if not os.path.exists(cv_dir):\n",
    "        print(f\"âš ï¸ Data directory {cv_dir} does not exist!\")\n",
    "        print(\"Creating the directory now...\")\n",
    "        os.makedirs(cv_dir, exist_ok=True)\n",
    "    \n",
    "    # Find all supported CV file formats\n",
    "    cv_files = []\n",
    "    supported_extensions = doc_processor.supported_extensions.keys()\n",
    "    \n",
    "    for file in os.listdir(cv_dir):\n",
    "        _, ext = os.path.splitext(file.lower())\n",
    "        if ext in supported_extensions:\n",
    "            cv_files.append(file)\n",
    "    \n",
    "    # Display results\n",
    "    if cv_files:\n",
    "        print(f\"ðŸ“Š Found {len(cv_files)} CV files in various formats\")\n",
    "        \n",
    "        # Group by file type for reporting\n",
    "        format_counts = {}\n",
    "        for file in cv_files:\n",
    "            _, ext = os.path.splitext(file.lower())\n",
    "            format_counts[ext] = format_counts.get(ext, 0) + 1\n",
    "        \n",
    "        print(\"\\nCV files available for processing:\")\n",
    "        for i, file in enumerate(cv_files, 1):\n",
    "            _, ext = os.path.splitext(file.lower())\n",
    "            format_name = doc_processor.supported_extensions[ext].value.capitalize()\n",
    "            print(f\"{i}. {file} ({format_name})\")\n",
    "        \n",
    "        print(f\"\\nðŸ“ Format breakdown:\")\n",
    "        for ext, count in format_counts.items():\n",
    "            format_name = doc_processor.supported_extensions[ext].value.capitalize()\n",
    "            print(f\"   - {format_name} ({ext}): {count} files\")\n",
    "    else:\n",
    "        print(f\"âš ï¸ No CV files found in {cv_dir}/\")\n",
    "        print(\"Please add sample CV files in supported formats to this folder.\")\n",
    "    \n",
    "    return cv_files\n",
    "\n",
    "# List all available CV files\n",
    "all_cv_files = list_all_cv_files()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e233388f",
   "metadata": {},
   "source": [
    "## Project 2: Enhanced CV Analyzer Implementation ðŸš€\n",
    "\n",
    "Building on Project 1's foundation, our enhanced analyzer can now:\n",
    "1. Process multiple document formats (PDF, Word, Excel, Text)\n",
    "2. Extract more detailed candidate information\n",
    "3. Perform weighted scoring for role matching\n",
    "4. Generate comprehensive visualizations and reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282d0479",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project 2: Enhanced Multi-Format CV Analyzer\n",
    "\n",
    "class Project2_EnhancedAnalyzer:\n",
    "    \"\"\"\n",
    "    Enhanced CV analyzer with multi-format support\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, doc_processor):\n",
    "        self.doc_processor = doc_processor\n",
    "        self.results = []\n",
    "        self.processed_count = 0\n",
    "        self.industry_context = {\n",
    "            \"current_market_trends\": \"High demand for cloud, AI, and cybersecurity skills\",\n",
    "            \"technical_evolution\": \"Rapid adoption of containerization, microservices, and DevOps practices\",\n",
    "            \"soft_skills_importance\": \"Growing emphasis on communication, collaboration, and adaptability\"\n",
    "        }\n",
    "        print(\"ðŸŸ¡ Project 2: Enhanced Multi-Format Analyzer initialized!\")\n",
    "    \n",
    "    def process_cv(self, file_path: str) -> dict:\n",
    "        \"\"\"\n",
    "        Process a CV file of any supported format\n",
    "        \n",
    "        Args:\n",
    "            file_path (str): Path to the CV file\n",
    "            \n",
    "        Returns:\n",
    "            dict: Complete candidate analysis\n",
    "        \"\"\"\n",
    "        print(f\"\\nðŸš€ Processing CV: {os.path.basename(file_path)}\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        # Step 1: Detect format and extract text\n",
    "        format_type = self.doc_processor.detect_format(file_path)\n",
    "        print(f\"ðŸ“„ Detected format: {format_type.value}\")\n",
    "        \n",
    "        if format_type == DocumentFormat.UNKNOWN:\n",
    "            return {\"error\": \"Unsupported file format\"}\n",
    "        \n",
    "        # Step 2: Extract text content based on format\n",
    "        cv_text = self.doc_processor.extract_text_from_file(file_path)\n",
    "        if not cv_text:\n",
    "            return {\"error\": \"Failed to extract text from file\"}\n",
    "        \n",
    "        # Step 3: Extract enhanced entities\n",
    "        entities = self.extract_enhanced_entities(cv_text)\n",
    "        if \"error\" in entities:\n",
    "            return entities\n",
    "        \n",
    "        # Step 4: Perform advanced role classification for all roles\n",
    "        from project1_basic_extraction import JobRole, ROLE_DEFINITIONS  # Import from Project 1\n",
    "        \n",
    "        role_analyses = {}\n",
    "        for role in JobRole:\n",
    "            analysis = self.classify_for_role_advanced(entities, role)\n",
    "            role_analyses[role.value] = analysis\n",
    "        \n",
    "        # Step 5: Determine best fit role with weighted scoring\n",
    "        best_role = self.find_best_role_match_weighted(role_analyses)\n",
    "        \n",
    "        # Compile complete profile with enhanced data\n",
    "        complete_profile = {\n",
    "            \"candidate_info\": entities,\n",
    "            \"role_analyses\": role_analyses,\n",
    "            \"best_role_match\": best_role,\n",
    "            \"format_type\": format_type.value,\n",
    "            \"processed_at\": datetime.now().isoformat(),\n",
    "            \"source_file\": os.path.basename(file_path)\n",
    "        }\n",
    "        \n",
    "        self.processed_count += 1\n",
    "        self.results.append(complete_profile)\n",
    "        \n",
    "        print(f\"âœ… CV processing completed! Best fit: {best_role['role']} ({best_role['score']}% match)\")\n",
    "        return complete_profile\n",
    "    \n",
    "    def extract_enhanced_entities(self, cv_text: str) -> dict:\n",
    "        \"\"\"\n",
    "        Extract enhanced entities from CV text using AI\n",
    "        \n",
    "        Args:\n",
    "            cv_text (str): Raw CV content\n",
    "            \n",
    "        Returns:\n",
    "            dict: Extracted detailed entities\n",
    "        \"\"\"\n",
    "        if not llm:\n",
    "            return {\"error\": \"LLM not initialized\"}\n",
    "        \n",
    "        try:\n",
    "            print(\"ðŸ”„ Extracting enhanced entities from CV...\")\n",
    "            chain = LLMChain(llm=llm, prompt=enhanced_extraction_prompt)\n",
    "            result = chain.run(cv_text=cv_text)\n",
    "            \n",
    "            # Parse JSON response\n",
    "            try:\n",
    "                entities = json.loads(result.strip())\n",
    "                print(\"âœ… Enhanced entities extracted successfully\")\n",
    "                return entities\n",
    "            except json.JSONDecodeError:\n",
    "                print(\"âš ï¸ JSON parsing failed, using raw response\")\n",
    "                return {\"raw_response\": result.strip()}\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Error extracting enhanced entities: {str(e)}\")\n",
    "            return {\"error\": str(e)}\n",
    "    \n",
    "    def classify_for_role_advanced(self, candidate_profile: dict, target_role: \"JobRole\") -> dict:\n",
    "        \"\"\"\n",
    "        Perform advanced role classification with weighted scoring\n",
    "        \n",
    "        Args:\n",
    "            candidate_profile (dict): Extracted candidate information\n",
    "            target_role (JobRole): Role to evaluate against\n",
    "            \n",
    "        Returns:\n",
    "            dict: Advanced role fit analysis\n",
    "        \"\"\"\n",
    "        if not llm:\n",
    "            return {\"error\": \"LLM not initialized\"}\n",
    "        \n",
    "        # Import role definitions from Project 1\n",
    "        from project1_basic_extraction import ROLE_DEFINITIONS\n",
    "        role_req = ROLE_DEFINITIONS[target_role]\n",
    "        \n",
    "        try:\n",
    "            print(f\"ðŸŽ¯ Analyzing fit for {target_role.value} with advanced metrics...\")\n",
    "            \n",
    "            # Prepare role requirements summary\n",
    "            requirements_summary = {\n",
    "                \"role\": target_role.value,\n",
    "                \"required_skills\": role_req.required_skills,\n",
    "                \"preferred_skills\": role_req.preferred_skills,\n",
    "                \"min_experience\": role_req.min_experience,\n",
    "                \"education\": role_req.education_requirements,\n",
    "                \"soft_skills\": role_req.soft_skills\n",
    "            }\n",
    "            \n",
    "            chain = LLMChain(llm=llm, prompt=advanced_classification_prompt)\n",
    "            result = chain.run(\n",
    "                candidate_profile=json.dumps(candidate_profile, indent=2),\n",
    "                role_requirements=json.dumps(requirements_summary, indent=2),\n",
    "                industry_context=json.dumps(self.industry_context, indent=2)\n",
    "            )\n",
    "            \n",
    "            # Parse JSON response\n",
    "            try:\n",
    "                classification = json.loads(result.strip())\n",
    "                classification[\"target_role\"] = target_role.value\n",
    "                print(f\"âœ… Advanced role analysis completed - {classification.get('recommendation', 'Unknown')}\")\n",
    "                return classification\n",
    "            except json.JSONDecodeError:\n",
    "                print(\"âš ï¸ JSON parsing failed for advanced classification\")\n",
    "                return {\"target_role\": target_role.value, \"raw_response\": result.strip()}\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Error in advanced role classification: {str(e)}\")\n",
    "            return {\"target_role\": target_role.value, \"error\": str(e)}\n",
    "    \n",
    "    def find_best_role_match_weighted(self, role_analyses: dict) -> dict:\n",
    "        \"\"\"\n",
    "        Find the best role match using weighted scoring algorithm\n",
    "        \n",
    "        Args:\n",
    "            role_analyses (dict): All role analysis results\n",
    "            \n",
    "        Returns:\n",
    "            dict: Best matching role with detailed metrics\n",
    "        \"\"\"\n",
    "        best_role = {\n",
    "            \"role\": \"Unknown\", \n",
    "            \"score\": 0, \n",
    "            \"recommendation\": \"No match\",\n",
    "            \"skill_match\": 0,\n",
    "            \"experience_match\": 0\n",
    "        }\n",
    "        \n",
    "        for role_name, analysis in role_analyses.items():\n",
    "            try:\n",
    "                # Extract various scores for weighted calculation\n",
    "                if \"role_fit_score\" in analysis:\n",
    "                    overall_score = float(analysis.get(\"role_fit_score\", 0))\n",
    "                    skill_match = float(analysis.get(\"skill_match_percentage\", 0))\n",
    "                    exp_quality = float(analysis.get(\"experience_quality_score\", 0))\n",
    "                    \n",
    "                    # Apply weighted scoring (can be adjusted based on priorities)\n",
    "                    weighted_score = (\n",
    "                        overall_score * 0.5 + \n",
    "                        skill_match * 0.3 + \n",
    "                        exp_quality * 0.2\n",
    "                    )\n",
    "                    \n",
    "                    if weighted_score > best_role[\"score\"]:\n",
    "                        best_role = {\n",
    "                            \"role\": role_name,\n",
    "                            \"score\": weighted_score,\n",
    "                            \"recommendation\": analysis.get(\"recommendation\", \"Unknown\"),\n",
    "                            \"skill_match\": skill_match,\n",
    "                            \"experience_match\": exp_quality,\n",
    "                            \"technical_level\": analysis.get(\"technical_proficiency\", \"Unknown\")\n",
    "                        }\n",
    "            except (ValueError, TypeError):\n",
    "                continue\n",
    "        \n",
    "        return best_role\n",
    "    \n",
    "    def generate_candidate_visualization(self, candidate_result: dict) -> None:\n",
    "        \"\"\"\n",
    "        Generate visualization charts for candidate analysis\n",
    "        \n",
    "        Args:\n",
    "            candidate_result (dict): Complete candidate analysis\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Create figure with multiple subplots\n",
    "            fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "            \n",
    "            # Chart 1: Role fit comparison\n",
    "            roles = []\n",
    "            scores = []\n",
    "            \n",
    "            for role, analysis in candidate_result[\"role_analyses\"].items():\n",
    "                if \"role_fit_score\" in analysis:\n",
    "                    try:\n",
    "                        score = float(analysis[\"role_fit_score\"])\n",
    "                        roles.append(role)\n",
    "                        scores.append(score)\n",
    "                    except (ValueError, TypeError):\n",
    "                        continue\n",
    "            \n",
    "            # Sort by score for better visualization\n",
    "            sorted_data = sorted(zip(roles, scores), key=lambda x: x[1])\n",
    "            roles, scores = zip(*sorted_data) if sorted_data else ([], [])\n",
    "            \n",
    "            bars = ax1.barh(roles, scores, color='skyblue')\n",
    "            ax1.set_xlim(0, 100)\n",
    "            ax1.set_xlabel('Match Score (%)')\n",
    "            ax1.set_title('Role Fit Analysis')\n",
    "            \n",
    "            # Add value labels\n",
    "            for bar in bars:\n",
    "                width = bar.get_width()\n",
    "                label_x_pos = width + 1\n",
    "                ax1.text(label_x_pos, bar.get_y() + bar.get_height()/2, f'{width:.0f}%',\n",
    "                        va='center')\n",
    "            \n",
    "            # Chart 2: Skill breakdown for best role\n",
    "            best_role = candidate_result[\"best_role_match\"][\"role\"]\n",
    "            best_role_analysis = candidate_result[\"role_analyses\"][best_role]\n",
    "            \n",
    "            if \"matching_skills\" in best_role_analysis and \"missing_skills\" in best_role_analysis:\n",
    "                matching = len(best_role_analysis[\"matching_skills\"])\n",
    "                missing = len(best_role_analysis[\"missing_skills\"])\n",
    "                \n",
    "                ax2.pie([matching, missing], \n",
    "                        labels=['Matching Skills', 'Missing Skills'],\n",
    "                        autopct='%1.1f%%',\n",
    "                        colors=['#66b3ff', '#ff9999'])\n",
    "                ax2.set_title(f'Skill Analysis for {best_role}')\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            \n",
    "            # Save the visualization\n",
    "            candidate_name = candidate_result[\"candidate_info\"].get(\"name\", \"unknown\").replace(\" \", \"_\").lower()\n",
    "            output_dir = \"output/visualizations\"\n",
    "            os.makedirs(output_dir, exist_ok=True)\n",
    "            \n",
    "            fig_path = os.path.join(output_dir, f\"{candidate_name}_analysis.png\")\n",
    "            plt.savefig(fig_path)\n",
    "            plt.close()\n",
    "            \n",
    "            print(f\"ðŸ“Š Candidate visualization saved to {fig_path}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Error generating visualization: {str(e)}\")\n",
    "    \n",
    "    def generate_enhanced_reports(self) -> None:\n",
    "        \"\"\"\n",
    "        Generate enhanced HTML and JSON reports for all processed candidates\n",
    "        \"\"\"\n",
    "        if not self.results:\n",
    "            print(\"âŒ No results to generate reports\")\n",
    "            return\n",
    "        \n",
    "        output_dir = \"output/enhanced_reports\"\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        \n",
    "        # Generate individual HTML reports for each candidate\n",
    "        for result in self.results:\n",
    "            candidate_name = result[\"candidate_info\"].get(\"name\", \"unknown\").replace(\" \", \"_\").lower()\n",
    "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "            \n",
    "            # Save detailed JSON report\n",
    "            json_path = os.path.join(output_dir, f\"{candidate_name}_{timestamp}.json\")\n",
    "            with open(json_path, 'w', encoding='utf-8') as f:\n",
    "                json.dump(result, f, indent=2)\n",
    "            \n",
    "            # Generate HTML report with visualizations\n",
    "            html_path = os.path.join(output_dir, f\"{candidate_name}_{timestamp}.html\")\n",
    "            self._create_html_report(result, html_path)\n",
    "            \n",
    "            print(f\"ðŸ“„ Enhanced reports generated for {candidate_name}\")\n",
    "    \n",
    "    def _create_html_report(self, result: dict, output_path: str) -> None:\n",
    "        \"\"\"\n",
    "        Create an HTML report for a candidate\n",
    "        \n",
    "        Args:\n",
    "            result (dict): Candidate analysis result\n",
    "            output_path (str): Path to save the HTML report\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Generate visualization for the report\n",
    "            self.generate_candidate_visualization(result)\n",
    "            \n",
    "            # Get candidate info\n",
    "            candidate = result[\"candidate_info\"]\n",
    "            best_role = result[\"best_role_match\"]\n",
    "            \n",
    "            # Create HTML content\n",
    "            html_content = f\"\"\"\n",
    "            <!DOCTYPE html>\n",
    "            <html>\n",
    "            <head>\n",
    "                <title>CV Analysis Report: {candidate.get('name', 'Candidate')}</title>\n",
    "                <style>\n",
    "                    body {{ font-family: Arial, sans-serif; margin: 40px; line-height: 1.6; }}\n",
    "                    h1, h2, h3 {{ color: #2c3e50; }}\n",
    "                    .container {{ max-width: 1000px; margin: 0 auto; }}\n",
    "                    .header {{ background-color: #3498db; color: white; padding: 20px; border-radius: 5px; }}\n",
    "                    .section {{ margin: 20px 0; padding: 20px; border: 1px solid #ddd; border-radius: 5px; }}\n",
    "                    .score-high {{ color: green; font-weight: bold; }}\n",
    "                    .score-medium {{ color: orange; font-weight: bold; }}\n",
    "                    .score-low {{ color: red; font-weight: bold; }}\n",
    "                    table {{ width: 100%; border-collapse: collapse; margin: 20px 0; }}\n",
    "                    th, td {{ border: 1px solid #ddd; padding: 8px; text-align: left; }}\n",
    "                    th {{ background-color: #f2f2f2; }}\n",
    "                    .visualization {{ text-align: center; margin: 30px 0; }}\n",
    "                </style>\n",
    "            </head>\n",
    "            <body>\n",
    "                <div class=\"container\">\n",
    "                    <div class=\"header\">\n",
    "                        <h1>CV Analysis Report</h1>\n",
    "                        <p>Generated on {datetime.now().strftime('%Y-%m-%d %H:%M')}</p>\n",
    "                    </div>\n",
    "                    \n",
    "                    <div class=\"section\">\n",
    "                        <h2>Candidate Profile</h2>\n",
    "                        <table>\n",
    "                            <tr><td><strong>Name</strong></td><td>{candidate.get('name', 'N/A')}</td></tr>\n",
    "                            <tr><td><strong>Contact</strong></td><td>Email: {candidate.get('email', 'N/A')}<br>Phone: {candidate.get('phone', 'N/A')}</td></tr>\n",
    "                            <tr><td><strong>Location</strong></td><td>{candidate.get('location', 'N/A')}</td></tr>\n",
    "                            <tr><td><strong>Experience</strong></td><td>{candidate.get('total_experience_years', 'N/A')} years</td></tr>\n",
    "                        </table>\n",
    "                        \n",
    "                        <h3>Skills</h3>\n",
    "                        <p>{', '.join(candidate.get('skills', ['No skills listed']))}</p>\n",
    "                        \n",
    "                        <h3>Experience</h3>\n",
    "                        <table>\n",
    "                            <tr>\n",
    "                                <th>Company</th>\n",
    "                                <th>Position</th>\n",
    "                                <th>Duration</th>\n",
    "                                <th>Responsibilities</th>\n",
    "                            </tr>\n",
    "            \"\"\"\n",
    "            \n",
    "            # Add experience entries\n",
    "            for exp in candidate.get('experience', []):\n",
    "                html_content += f\"\"\"\n",
    "                            <tr>\n",
    "                                <td>{exp.get('company', 'N/A')}</td>\n",
    "                                <td>{exp.get('position', 'N/A')}</td>\n",
    "                                <td>{exp.get('duration', 'N/A')}</td>\n",
    "                                <td>{exp.get('responsibilities', 'N/A')}</td>\n",
    "                            </tr>\n",
    "                \"\"\"\n",
    "            \n",
    "            if not candidate.get('experience'):\n",
    "                html_content += \"\"\"\n",
    "                            <tr>\n",
    "                                <td colspan=\"4\">No experience data available</td>\n",
    "                            </tr>\n",
    "                \"\"\"\n",
    "            \n",
    "            html_content += \"\"\"\n",
    "                        </table>\n",
    "                        \n",
    "                        <h3>Education</h3>\n",
    "                        <table>\n",
    "                            <tr>\n",
    "                                <th>Degree</th>\n",
    "                                <th>Institution</th>\n",
    "                                <th>Year</th>\n",
    "                                <th>Field</th>\n",
    "                            </tr>\n",
    "            \"\"\"\n",
    "            \n",
    "            # Add education entries\n",
    "            for edu in candidate.get('education', []):\n",
    "                html_content += f\"\"\"\n",
    "                            <tr>\n",
    "                                <td>{edu.get('degree', 'N/A')}</td>\n",
    "                                <td>{edu.get('institution', 'N/A')}</td>\n",
    "                                <td>{edu.get('year', 'N/A')}</td>\n",
    "                                <td>{edu.get('field', 'N/A')}</td>\n",
    "                            </tr>\n",
    "                \"\"\"\n",
    "            \n",
    "            if not candidate.get('education'):\n",
    "                html_content += \"\"\"\n",
    "                            <tr>\n",
    "                                <td colspan=\"4\">No education data available</td>\n",
    "                            </tr>\n",
    "                \"\"\"\n",
    "            \n",
    "            html_content += \"\"\"\n",
    "                        </table>\n",
    "                    </div>\n",
    "                    \n",
    "                    <div class=\"section\">\n",
    "                        <h2>Role Analysis</h2>\n",
    "                        <h3>Best Role Match</h3>\n",
    "                        <p>\n",
    "                            <strong>Role:</strong> {0}<br>\n",
    "                            <strong>Match Score:</strong> <span class=\"{1}\">{2}%</span><br>\n",
    "                            <strong>Recommendation:</strong> {3}<br>\n",
    "                            <strong>Technical Level:</strong> {4}\n",
    "                        </p>\n",
    "                        \n",
    "                        <h3>Role Comparison</h3>\n",
    "                        <div class=\"visualization\">\n",
    "                            <img src=\"../visualizations/{5}_analysis.png\" alt=\"Candidate Analysis Chart\" style=\"max-width: 100%;\">\n",
    "                        </div>\n",
    "                    </div>\n",
    "                    \n",
    "                    <div class=\"section\">\n",
    "                        <h2>Recommendation</h2>\n",
    "            \"\"\".format(\n",
    "                best_role['role'],\n",
    "                'score-high' if best_role['score'] >= 75 else 'score-medium' if best_role['score'] >= 50 else 'score-low',\n",
    "                round(best_role['score']),\n",
    "                best_role['recommendation'],\n",
    "                best_role.get('technical_level', 'N/A'),\n",
    "                candidate.get('name', 'unknown').replace(\" \", \"_\").lower()\n",
    "            )\n",
    "            \n",
    "            # Get the best role analysis details\n",
    "            best_role_name = best_role['role']\n",
    "            best_role_analysis = result[\"role_analyses\"][best_role_name]\n",
    "            \n",
    "            html_content += f\"\"\"\n",
    "                        <h3>Strengths</h3>\n",
    "                        <ul>\n",
    "            \"\"\"\n",
    "            \n",
    "            # Add strengths\n",
    "            for strength in best_role_analysis.get('strengths', []):\n",
    "                html_content += f\"<li>{strength}</li>\\n\"\n",
    "            \n",
    "            if not best_role_analysis.get('strengths'):\n",
    "                html_content += \"<li>No specific strengths identified</li>\\n\"\n",
    "            \n",
    "            html_content += \"\"\"\n",
    "                        </ul>\n",
    "                        \n",
    "                        <h3>Areas for Development</h3>\n",
    "                        <ul>\n",
    "            \"\"\"\n",
    "            \n",
    "            # Add growth areas\n",
    "            for area in best_role_analysis.get('growth_areas', best_role_analysis.get('concerns', [])):\n",
    "                html_content += f\"<li>{area}</li>\\n\"\n",
    "            \n",
    "            if not best_role_analysis.get('growth_areas') and not best_role_analysis.get('concerns'):\n",
    "                html_content += \"<li>No specific development areas identified</li>\\n\"\n",
    "            \n",
    "            html_content += \"\"\"\n",
    "                        </ul>\n",
    "                        \n",
    "                        <h3>Interview Focus Areas</h3>\n",
    "                        <ul>\n",
    "            \"\"\"\n",
    "            \n",
    "            # Add interview focus areas\n",
    "            for area in best_role_analysis.get('interview_focus_areas', []):\n",
    "                html_content += f\"<li>{area}</li>\\n\"\n",
    "            \n",
    "            if not best_role_analysis.get('interview_focus_areas'):\n",
    "                html_content += \"<li>No specific interview focus areas suggested</li>\\n\"\n",
    "            \n",
    "            html_content += \"\"\"\n",
    "                        </ul>\n",
    "                        \n",
    "                        <h3>Justification</h3>\n",
    "                        <p>\n",
    "                            {0}\n",
    "                        </p>\n",
    "                    </div>\n",
    "                    \n",
    "                    <div class=\"section\">\n",
    "                        <h3>Processing Information</h3>\n",
    "                        <p>\n",
    "                            <strong>Source File:</strong> {1}<br>\n",
    "                            <strong>Format Type:</strong> {2}<br>\n",
    "                            <strong>Processed At:</strong> {3}\n",
    "                        </p>\n",
    "                    </div>\n",
    "                </div>\n",
    "            </body>\n",
    "            </html>\n",
    "            \"\"\".format(\n",
    "                best_role_analysis.get('justification', 'No justification provided.'),\n",
    "                result['source_file'],\n",
    "                result['format_type'].capitalize(),\n",
    "                result['processed_at']\n",
    "            )\n",
    "            \n",
    "            # Write HTML to file\n",
    "            with open(output_path, 'w', encoding='utf-8') as f:\n",
    "                f.write(html_content)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Error creating HTML report: {str(e)}\")\n",
    "\n",
    "# Initialize the enhanced analyzer\n",
    "project2_analyzer = Project2_EnhancedAnalyzer(doc_processor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd23b4db",
   "metadata": {},
   "source": [
    "## Process All CV Files ðŸš€\n",
    "\n",
    "Now let's process all available CV files with our enhanced multi-format analyzer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa7df46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process all available CV files with enhanced analyzer\n",
    "\n",
    "def process_all_cv_files():\n",
    "    \"\"\"\n",
    "    Process all CV files in the data/cvs folder with the enhanced analyzer\n",
    "    \"\"\"\n",
    "    print(\"\\nðŸš€ Starting Enhanced Multi-Format CV Analysis\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Check if API key is available\n",
    "    if not openai_api_key:\n",
    "        print(\"âŒ OpenAI API key not configured\")\n",
    "        print(\"Please set up your config.txt file with OPENAI_API_KEY\")\n",
    "        return\n",
    "    \n",
    "    # Get all CV files from data folder\n",
    "    cv_dir = os.path.join('data', 'cvs')\n",
    "    cv_files = []\n",
    "    \n",
    "    if os.path.exists(cv_dir):\n",
    "        for file in os.listdir(cv_dir):\n",
    "            # Only include supported formats\n",
    "            format_type = doc_processor.detect_format(file)\n",
    "            if format_type != DocumentFormat.UNKNOWN:\n",
    "                cv_files.append(file)\n",
    "    \n",
    "    if not cv_files:\n",
    "        print(\"âŒ No CV files found in data/cvs/\")\n",
    "        print(\"Please add CV files in supported formats to continue.\")\n",
    "        return\n",
    "    \n",
    "    # Display processing information\n",
    "    print(f\"ðŸ“„ Processing {len(cv_files)} CV files with enhanced multi-format analyzer\")\n",
    "    \n",
    "    # Process each CV\n",
    "    for cv_file in cv_files:\n",
    "        cv_path = os.path.join(cv_dir, cv_file)\n",
    "        result = project2_analyzer.process_single_cv(cv_path)\n",
    "        \n",
    "        if \"error\" not in result:\n",
    "            print(f\"\\nðŸ“Š Enhanced Results for {cv_file}:\")\n",
    "            print(f\"- Name: {result['candidate_info'].get('name', 'Not found')}\")\n",
    "            print(f\"- Best Role: {result['best_role_match']['role']} ({result['best_role_match']['score']:.1f}% fit)\")\n",
    "            print(f\"- Technical Level: {result['best_role_match'].get('technical_level', 'Unknown')}\")\n",
    "            print(f\"- Format: {result['format_type'].capitalize()}\")\n",
    "    \n",
    "    # Generate enhanced reports\n",
    "    project2_analyzer.generate_enhanced_reports()\n",
    "    \n",
    "    print(f\"\\nâœ… Enhanced CV Analysis completed! Processed {project2_analyzer.processed_count} CVs\")\n",
    "    print(\"   Enhanced HTML and JSON reports have been generated in output/enhanced_reports\")\n",
    "\n",
    "# Define the method for processing a single CV (needed for the class)\n",
    "def process_single_cv(self, cv_file_path: str) -> dict:\n",
    "    \"\"\"\n",
    "    Complete enhanced processing pipeline for a single CV.\n",
    "    \n",
    "    Args:\n",
    "        cv_file_path (str): Path to CV file\n",
    "        \n",
    "    Returns:\n",
    "        dict: Complete candidate analysis\n",
    "    \"\"\"\n",
    "    return self.process_cv(cv_file_path)\n",
    "\n",
    "# Add the method to the Project2_EnhancedAnalyzer class\n",
    "Project2_EnhancedAnalyzer.process_single_cv = process_single_cv\n",
    "\n",
    "# Run the analysis on all CV files\n",
    "if all_cv_files:  # Only run if CV files were found\n",
    "    process_all_cv_files()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b1a981c",
   "metadata": {},
   "source": [
    "## ðŸŽ‰ Project 2 Conclusion\n",
    "\n",
    "In this advanced project, you've built a sophisticated CV analysis system that:\n",
    "\n",
    "âœ… **Processes multiple document formats** (PDF, Word, Excel, Text)  \n",
    "âœ… **Extracts enriched candidate information** with greater detail  \n",
    "âœ… **Applies advanced weighted scoring** for more accurate role matching  \n",
    "âœ… **Generates visual analytics** to aid decision making  \n",
    "âœ… **Produces professional HTML reports** for hiring managers  \n",
    "\n",
    "This enhanced system demonstrates how to scale your HR automation from Project 1's basic functionality to an enterprise-grade solution that can handle the diverse document formats and complex analysis needs of modern HR departments.\n",
    "\n",
    "### Complete CV Analyzer System\n",
    "\n",
    "You now have a complete CV Analyzer system with:\n",
    "\n",
    "1. **Project 1**: Basic text-based CV analysis with role matching  \n",
    "2. **Project 2**: Advanced multi-format document processing with enhanced reporting  \n",
    "\n",
    "Together, these projects form a comprehensive HR automation solution that significantly reduces the time and effort required for candidate evaluation while increasing consistency and accuracy.\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "To expand this system further:\n",
    "\n",
    "1. **Add a web interface** for easier interaction\n",
    "2. **Implement candidate database** for long-term storage\n",
    "3. **Add collaborative features** for team-based hiring\n",
    "4. **Incorporate interview scheduling** and feedback collection\n",
    "5. **Develop talent pool analytics** for strategic HR planning"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
